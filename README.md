ControleBet + IoT/IOB â€“ Aposta Consciente (XP)

App mobile em React Native (Expo) integrado a um gateway IoT (FastAPI) que recebe eventos de anÃ¡lise facial (OpenCV) para incentivar apostas responsÃ¡veis.
Quando o mÃ³dulo facial detecta estresse acima do limiar, ele envia eventos Ã  API â€“ que o app consome â€“ e o usuÃ¡rio recebe orientaÃ§Ãµes (ex.: Pausa guiada (respiraÃ§Ã£o 60s)).

ðŸ”— MÃ³dulos do projeto
MÃ³dulo	Pasta	FunÃ§Ã£o	Tecnologias
Mobile (ControleBet)	Sprint-MobileDevelop/	App do usuÃ¡rio; dashboards, metas, perfil de risco	React Native, Expo, TypeScript
Gateway IoT (API)	Mobile_Challange-main/Mobile_Challange-main/	Recebe POST /events, expÃµe GET /events/last	FastAPI, Uvicorn
AnÃ¡lise Facial	Mobile_Challange-main/Mobile_Challange-main/	Processa vÃ­deo, calcula stress score e envia para API	Python, OpenCV, NumPy

Importante: se vocÃª nÃ£o tem webcam, use um arquivo de vÃ­deo (ex.: face_400.mp4).

ðŸ§  Como a integraÃ§Ã£o funciona
flowchart LR
U[UsuÃ¡rio (vÃ­deo/rosto)] --> F[OpenCV Python<br/>main_no_mediapipe.py]
F -- POST JSON --> A[FastAPI (IoT Gateway)<br/>/events, /events/last]
A -- GET JSON --> M[App Mobile (ControleBet)]
M --> UI[UI: alertas, metas, status]


O Python (OpenCV) calcula um score âˆˆ [0..1] e classifica:
leve (score < threshold), medio (score < 0.70), alto (â‰¥ 0.70)

Envia payloads para a API:
{
  "deviceId": "xp-edge-01",
  "userId": "admin",
  "score": 0.72,
  "level": "alto",
  "route": "Pausa guiada (respiracao 60s)",
  "ts": 1734636000
}


O app consulta /events/last periodicamente e exibe as recomendaÃ§Ãµes.
âœ… PrÃ©-requisitos
Node.js 18+ (para o app mobile)
Python 3.10+ (recomendado 3.10 ou 3.11 para mÃ¡xima compatibilidade)
pip atualizado
Expo CLI (npx expo)
(Opcional) Android Studio/Xcode para emuladores

ðŸ› ï¸ InstalaÃ§Ã£o das dependÃªncias (uma vez)
API + Facial (Python)
No Windows/PowerShell:

# VÃ¡ para a pasta da API/facial
cd "C:\Users\Meu Computador\Downloads\Mobile_Challange-main\Mobile_Challange-main"

# Crie e ative um venv
python -m venv .venv
.\.venv\Scripts\activate

# Instale libs
pip install --upgrade pip
pip install fastapi uvicorn requests opencv-python numpy

Mobile (React Native)

No diretÃ³rio do app:
cd "C:\caminho\para\Sprint-MobileDevelop"
npm install --legacy-peer-deps

# DependÃªncias do Expo usadas no projeto
npx expo install react-native-screens react-native-safe-area-context

â–¶ï¸ Como rodar os 3 mÃ³dulos (ordem recomendada)
1) Inicie o Gateway IoT (API FastAPI)
cd "C:\Users\Meu Computador\Downloads\Mobile_Challange-main\Mobile_Challange-main"
.\.venv\Scripts\activate
python -m uvicorn api:app --host 127.0.0.1 --port 8081 --reload


Teste no navegador: http://127.0.0.1:8081/docs
VocÃª verÃ¡ o Swagger com:
POST /events (recebe eventos do facial)
GET /events/last (Ãºltimo evento, para o Mobile consumir)
Teste rÃ¡pido via PowerShell:

$body = @{
  deviceId = "xp-edge-01"
  userId   = "admin"
  score    = 0.72
  level    = "alto"
  route    = "Pausa guiada (respiracao 60s)"
  ts       = [int][double]::Parse((Get-Date -UFormat %s))
} | ConvertTo-Json

Invoke-RestMethod -Uri "http://127.0.0.1:8081/events" -Method Post -Body $body -ContentType "application/json"
Invoke-RestMethod -Uri "http://127.0.0.1:8081/events/last" -Method Get

2) Rode o processador facial (OpenCV)

Com o mesmo venv ativado:

# ainda em Mobile_Challange-main\Mobile_Challange-main
python .\main_no_mediapipe.py --video ".\face_400.mp4" --width 400 --api "http://127.0.0.1:8081" --user-id admin --device-id xp-edge-01 --push-interval 1.0 --threshold 0.35 --csv ".\scores_face.csv"


VocÃª deve ver:
Janela do vÃ­deo com retÃ¢ngulo no rosto;
Painel lateral com score/nÃ­vel/sugestÃ£o;
No terminal da API, POST /events 200 aparecendo.
Sem webcam? Sem problemas. O comando acima jÃ¡ usa face_400.mp4.
Sem GUI? Gere um vÃ­deo processado:
--out-video ".\output_face.mp4"

3) Rode o app Mobile (ControleBet)
cd "C:\caminho\para\Sprint-MobileDevelop"
npx expo start


Aponte o app para a API (duas opÃ§Ãµes):
OpÃ§Ã£o A â€“ Arquivo de configuraÃ§Ã£o
Crie .env na raiz do app:

EXPO_PUBLIC_API_BASE=http://127.0.0.1:8081

E no cÃ³digo (ex. services/api.ts):
export const API_BASE = process.env.EXPO_PUBLIC_API_BASE ?? "http://127.0.0.1:8081";


OpÃ§Ã£o B â€“ Valor fixo em cÃ³digo (rÃ¡pido)
export const API_BASE = "http://127.0.0.1:8081";


Consumo do evento no app (exemplo de polling a cada 5s):

// services/events.ts
export async function fetchLastEvent() {
  const res = await fetch(`${API_BASE}/events/last`);
  if (!res.ok) throw new Error("API error");
  return res.json();
}

// Em Home.tsx (ou Context)
useEffect(() => {
  let isMounted = true;
  const tick = async () => {
    try {
      const data = await fetchLastEvent();
      if (isMounted && data?.level) setStressInfo(data); // exibe no UI
    } catch {}
  };
  tick();
  const id = setInterval(tick, 5000);
  return () => { isMounted = false; clearInterval(id); };
}, []);


Abra no Expo Go (QR), Android emulator (a) ou iOS simulator (i).
Credenciais de teste (app):
UsuÃ¡rio: admin
Senha: 12345

ðŸ“¡ Endpoints expostos pela API

POST /events â€“ recebe um evento do facial
Body (JSON):

{
  "deviceId": "xp-edge-01",
  "userId": "admin",
  "score": 0.55,
  "level": "medio",
  "route": "Pausa guiada (respiracao 60s)",
  "ts": 1734636000
}


GET /events/last â€“ retorna o Ãºltimo evento recebido
Exemplo de resposta:

{
  "ok": true,
  "event": {
    "deviceId": "xp-edge-01",
    "userId": "admin",
    "score": 0.72,
    "level": "alto",
    "route": "Pausa guiada (respiracao 60s)",
    "ts": 1734636000
  }
}

ðŸ§® Como o score e o nÃ­vel funcionam (facial)

Score âˆˆ [0..1] calculado por heurÃ­stica leve:

jitter (variaÃ§Ã£o quadro a quadro no ROI facial),

mouth_open (brilho mÃ©dio metade inferior âˆ’ superior na regiÃ£o da boca).

NÃ­veis:
leve â†’ score < --threshold (padrÃ£o 0.35)
medio â†’ score < 0.70
alto â†’ score â‰¥ 0.70

SugestÃ£o:
leve â†’ â€œContinuar tranquiloâ€
medio/alto â†’ â€œPausa guiada (respiracao 60s)â€

ðŸ§ª Roteiro de demo (atÃ© 5 min)
Arquitetura (30â€“45s): mostre o diagrama (Flowchart).
API (30s): rode o Uvicorn e abra http://127.0.0.1:8081/docs.
Facial (1â€“2min): rode main_no_mediapipe.py, mostre o vÃ­deo e os POST no terminal da API.
Mobile (1â€“2min): abra o app (Expo), mostre que a tela consome /events/last e atualiza sugestÃµes.
Fechamento (30s): reforÃ§o de uso responsÃ¡vel + prÃ³ximos passos (notificaÃ§Ãµes, dashboard, etc.).

ðŸ§¯ Troubleshooting rÃ¡pido
â€œNÃ£o abre vÃ­deoâ€: use check_video.py e teste com caminho absoluto; se necessÃ¡rio recodifique para H.264.
ModuleNotFoundError: cv2: instale opencv-python no mesmo venv ativo.
CORS no mobile: se testar em dispositivo fÃ­sico, troque 127.0.0.1 pelo IP da mÃ¡quina na mesma rede (ex.: http://192.168.15.123:8081) e use esse IP no .env do app.
Porta ocupada: mude --port no Uvicorn (ex.: 8082) e atualize API_BASE no app.
Sem webcam: passe --video "face_400.mp4" (jÃ¡ previsto).

ðŸ“¦ Tecnologias

Mobile: React Native, Expo, TypeScript, AsyncStorage, react-navigation, chart-kit, SVG
API: FastAPI, Uvicorn
Facial: Python, OpenCV, NumPy, Requests

ðŸ‘¥ Equipe

Irana Pereira â€“ RM98593
Lucas Vinicius â€“ RM98480
Mariana Melo â€“ RM98121
Mateus Iago â€“ RM550270

ðŸ“„ LicenÃ§a
Projeto acadÃªmico â€“ FIAP (2025). Uso educacional.
